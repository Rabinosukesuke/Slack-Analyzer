import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
import google.generativeai as genai
import os
import zipfile
import json
import csv
from pathlib import Path
import tempfile

st.set_page_config(page_title="Slackã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£åˆ†æ", page_icon="ğŸ˜„", layout="wide")

# Gemini APIã®è¨­å®š
api_key = os.environ.get("API_KEY")
genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-pro')

class User:
    def __init__(self, id, name, display_name, is_restricted, deleted):
        self.id = id
        self.name = name
        self.display_name = display_name
        self.is_restricted = is_restricted
        self.deleted = deleted

class Stats:
    def __init__(self, user_id, name, display_name, is_restricted, deleted):
        self.user_id = user_id
        self.name = name
        self.display_name = display_name
        self.posts = 0
        self.given_reactions = 0
        self.given_reaction_users = set()
        self.received_reactions = 0
        self.received_reaction_users = set()
        self.is_restricted = is_restricted
        self.deleted = deleted

def load_users(users_file):
    with open(users_file, 'r') as f:
        users_data = json.load(f)
    
    return {user['id']: User(user['id'], user.get('name', ''), 
                             user['profile']['display_name'], 
                             user.get('is_restricted', False), 
                             user.get('deleted', False)) 
            for user in users_data}

def read_messages_from_json_file(file_path):
    with open(file_path, 'r') as f:
        return json.load(f)

def update_stats(stats_by_channel, channel_name, messages, users):
    for message in messages:
        if not message.get('ts'):
            continue
        
        date = datetime.fromtimestamp(float(message['ts'])).strftime('%Y-%m-%d')
        user_id = message.get('user')
        
        if user_id not in users:
            continue
        
        if channel_name not in stats_by_channel:
            stats_by_channel[channel_name] = {}
        
        if date not in stats_by_channel[channel_name]:
            stats_by_channel[channel_name][date] = {}
        
        if user_id not in stats_by_channel[channel_name][date]:
            user = users[user_id]
            stats_by_channel[channel_name][date][user_id] = Stats(
                user.id, user.name, user.display_name, user.is_restricted, user.deleted
            )
        
        stats = stats_by_channel[channel_name][date][user_id]
        stats.posts += 1
        
        for reaction in message.get('reactions', []):
            for reacting_user in reaction['users']:
                if reacting_user not in stats_by_channel[channel_name][date]:
                    if reacting_user not in users:
                        continue
                    user = users[reacting_user]
                    stats_by_channel[channel_name][date][reacting_user] = Stats(
                        user.id, user.name, user.display_name, user.is_restricted, user.deleted
                    )
                
                reacting_stats = stats_by_channel[channel_name][date][reacting_user]
                reacting_stats.given_reactions += 1
                reacting_stats.given_reaction_users.add(user_id)
                
                stats.received_reactions += 1
                stats.received_reaction_users.add(reacting_user)

def process_slack_data(base_path):
    base_path = Path(base_path)
    stats_by_channel = {}
    
    users = load_users(base_path / 'users.json')
    
    for channel_dir in base_path.iterdir():
        if channel_dir.is_dir() and channel_dir.name != base_path.name:
            for json_file in channel_dir.glob('*.json'):
                messages = read_messages_from_json_file(json_file)
                update_stats(stats_by_channel, channel_dir.name, messages, users)
    
    return stats_by_channel

def export_csv(stats_by_channel, output_file):
    with open(output_file, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['display_name', 'name', 'is_restricted', 'deleted', 'day', 'posts',
                         'received_reactions', 'received_reaction_users', 'given_reactions',
                         'given_reaction_users', 'channel_name'])
        
        for channel_name, days in stats_by_channel.items():
            for day, users_stats in days.items():
                for stats in users_stats.values():
                    writer.writerow([
                        stats.display_name,
                        stats.name,
                        stats.is_restricted,
                        stats.deleted,
                        day,
                        stats.posts,
                        stats.received_reactions,
                        len(stats.received_reaction_users),
                        stats.given_reactions,
                        len(stats.given_reaction_users),
                        channel_name
                    ])

# å…¨ä½“çµ±è¨ˆã®è¨ˆç®—
def calculate_overall_stats(df):
    total_messages = len(df)
    total_reactions = df['received_reactions'].sum()
    active_users = df['display_name'].nunique()
    total_channels = df['channel_name'].nunique()
    avg_messages_per_day = df.groupby('day')['posts'].sum().mean()
    avg_reactions_per_message = total_reactions / total_messages if total_messages > 0 else 0
    
    return {
        "ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°": total_messages,
        "ç·ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°": total_reactions,
        "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°": active_users,
        "ç·ãƒãƒ£ãƒ³ãƒãƒ«æ•°": total_channels,
        "1æ—¥ã‚ãŸã‚Šã®å¹³å‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°": avg_messages_per_day,
        "1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ãŸã‚Šã®å¹³å‡ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°": avg_reactions_per_message
    }

# ãƒãƒ£ãƒ³ãƒãƒ«æˆé•·ç‡ã®è¨ˆç®—
def calculate_channel_growth(df, start_date, end_date, previous_start_date):
    current_messages = df[(df['day'] >= start_date) & (df['day'] <= end_date)].groupby('channel_name')['posts'].sum()
    previous_messages = df[(df['day'] >= previous_start_date) & (df['day'] < start_date)].groupby('channel_name')['posts'].sum()
    growth = ((current_messages - previous_messages) / previous_messages).fillna(0).sort_values(ascending=False)
    return growth[growth > 0.1]  # 10%ä»¥ä¸Šæˆé•·ã—ãŸãƒãƒ£ãƒ³ãƒãƒ«ã‚’è¡¨ç¤º

# ãƒ¦ãƒ¼ã‚¶ãƒ¼æˆé•·ç‡ã®è¨ˆç®—
def calculate_user_growth(df, start_date, end_date, previous_start_date):
    current_messages = df[(df['day'] >= start_date) & (df['day'] <= end_date)].groupby('display_name')['posts'].sum()
    previous_messages = df[(df['day'] >= previous_start_date) & (df['day'] < start_date)].groupby('display_name')['posts'].sum()
    
    # previous_messages ãŒ 0 ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’é™¤å¤–
    previous_messages = previous_messages[previous_messages != 0]

    # å…±é€šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿ã‚’ä½¿ç”¨
    common_users = current_messages.index.intersection(previous_messages.index)

    # æˆé•·ç‡ã‚’è¨ˆç®—
    growth = ((current_messages[common_users] - previous_messages[common_users]) / previous_messages[common_users]).fillna(0).sort_values(ascending=False)
    
    return growth[growth > 0.5]  # 50%ä»¥ä¸Šæˆé•·ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¡¨ç¤º

# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–¢æ•°
def generate_report(df, start_date, end_date, previous_start_date):
    current_df = df[(df['day'] >= start_date) & (df['day'] <= end_date)]
    previous_df = df[(df['day'] >= previous_start_date) & (df['day'] < start_date)]
    
    current_stats = calculate_overall_stats(current_df)
    previous_stats = calculate_overall_stats(previous_df)
    
    channel_growth = calculate_channel_growth(df, start_date, end_date, previous_start_date)
    user_growth = calculate_user_growth(df, start_date, end_date, previous_start_date)
    
    top_channels = current_df.groupby('channel_name')['posts'].sum().sort_values(ascending=False).head(5)
    top_users = current_df.groupby('display_name')['posts'].sum().sort_values(ascending=False).head(5)

    report_data = f"""
    Slackã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£åˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆ{start_date.strftime('%Y-%m-%d')} ã‹ã‚‰ {end_date.strftime('%Y-%m-%d')}ã¾ã§ï¼‰

    1. å…¨ä½“çµ±è¨ˆ:
       ç¾åœ¨ã®æœŸé–“:
       {current_stats}
       
       å‰ã®æœŸé–“ ({previous_start_date.strftime('%Y-%m-%d')} ã‹ã‚‰ {start_date.strftime('%Y-%m-%d')}ã¾ã§):
       {previous_stats}

    2. ãƒãƒ£ãƒ³ãƒãƒ«åˆ†æ:
       - ãƒˆãƒƒãƒ—5ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ï¼‰:
         {top_channels.to_string()}
       - æˆé•·ç‡ã®é«˜ã„ãƒãƒ£ãƒ³ãƒãƒ«:
         {channel_growth.to_string()}

    3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ:
       - ãƒˆãƒƒãƒ—5ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ï¼‰:
         {top_users.to_string()}
       - æˆé•·ç‡ã®é«˜ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼:
         {user_growth.to_string()}

    ã“ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚€ç·åˆçš„ãªåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„:

    1. å…¨ä½“çš„ãªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®å¥å…¨æ€§ã¨æˆé•·å‚¾å‘ï¼ˆå‰ã®æœŸé–“ã¨ã®æ¯”è¼ƒã‚’å«ã‚€ï¼‰
    2. ãƒãƒ£ãƒ³ãƒãƒ«ã®æ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æ–°ãŸãªãƒˆãƒ¬ãƒ³ãƒ‰
    3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã®ç‰¹å¾´ã¨å¤‰åŒ–
    4. æŠ•ç¨¿ã®å¤šã„æ—¥ã«ã¡ã‚„æ›œæ—¥
    5. ä»Šå¾Œã®æ”¹å–„ç‚¹

    ã‚ãªãŸã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚ãƒ¬ãƒãƒ¼ãƒˆã¯ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚„ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®æç¤ºã«é©ã—ãŸã€æ˜ç¢ºã§å®Ÿç”¨çš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
    """

    try:
        response = model.generate_content(report_data)
        return response.text
    except Exception as e:
        st.error(f"Gemini APIã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None
    
def main():
    st.title('Slackã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿åˆ†æ')
    
    uploaded_file = st.file_uploader("Slackãƒ‡ãƒ¼ã‚¿ã®zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type="zip")
    if uploaded_file is not None:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
            # Create a temporary directory
            with tempfile.TemporaryDirectory() as tmpdir:
                # Save the uploaded file
                zip_path = Path(tmpdir) / "slack_data.zip"
                zip_path.write_bytes(uploaded_file.getvalue())
                
                # Unzip the file
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extractall(tmpdir)
                
                # Process the data
                stats_by_channel = process_slack_data(tmpdir)
                
                # Export to CSV
                csv_path = Path(tmpdir) / "slack_data_analysis.csv"
                export_csv(stats_by_channel, csv_path)
                
                # Load the CSV file
                df = pd.read_csv(csv_path)
        
                st.success("ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # æ—¥ä»˜ç¯„å›²ã®é¸æŠ
        df['day'] = pd.to_datetime(df['day'])
        min_date = df['day'].min().date()
        max_date = df['day'].max().date()
        start_date = st.date_input("é–‹å§‹æ—¥", min_date, min_value=min_date, max_value=max_date)
        end_date = st.date_input("çµ‚äº†æ—¥", max_date, min_value=min_date, max_value=max_date)

        if start_date <= end_date:
            # start_dateã¨end_dateã‚’datetime64[ns]å‹ã«å¤‰æ›
            start_datetime = pd.to_datetime(start_date)
            end_datetime = pd.to_datetime(end_date) + timedelta(days=1) - timedelta(microseconds=1)
            
            df_filtered = df[(df['day'] >= start_datetime) & (df['day'] <= end_datetime)]
            date_diff = end_date - start_date
            previous_start_date = start_date - date_diff - timedelta(days=1)
            previous_start_datetime = pd.to_datetime(previous_start_date)
        else:
            st.error("ã‚¨ãƒ©ãƒ¼: çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
            return

        # å…¨ä½“çµ±è¨ˆ
        st.header("å…¨ä½“çµ±è¨ˆ")
        current_stats = calculate_overall_stats(df_filtered)
        previous_df = df[(df['day'] >= previous_start_datetime) & (df['day'] < start_datetime)]
        previous_stats = calculate_overall_stats(previous_df)
    
        col1, col2, col3 = st.columns(3)
        col1.metric("ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", f"{current_stats['ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°']:,}", f"{current_stats['ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°'] - previous_stats['ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°']:,}")
        col2.metric("ç·ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°", f"{current_stats['ç·ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°']:,}", f"{current_stats['ç·ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°'] - previous_stats['ç·ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°']:,}")
        col3.metric("ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°", f"{current_stats['ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°']:,}", f"{current_stats['ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°'] - previous_stats['ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°']:,}")

        col4, col5, col6 = st.columns(3)
        col4.metric("ç·ãƒãƒ£ãƒ³ãƒãƒ«æ•°", f"{current_stats['ç·ãƒãƒ£ãƒ³ãƒãƒ«æ•°']:,}", f"{current_stats['ç·ãƒãƒ£ãƒ³ãƒãƒ«æ•°'] - previous_stats['ç·ãƒãƒ£ãƒ³ãƒãƒ«æ•°']:,}")
        col5.metric("1æ—¥ã‚ãŸã‚Šã®å¹³å‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", f"{current_stats['1æ—¥ã‚ãŸã‚Šã®å¹³å‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°']:.2f}", f"{current_stats['1æ—¥ã‚ãŸã‚Šã®å¹³å‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°'] - previous_stats['1æ—¥ã‚ãŸã‚Šã®å¹³å‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°']:.2f}")
        col6.metric("1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ãŸã‚Šã®å¹³å‡ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°", f"{current_stats['1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ãŸã‚Šã®å¹³å‡ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°']:.2f}", f"{current_stats['1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ãŸã‚Šã®å¹³å‡ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°'] - previous_stats['1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ãŸã‚Šã®å¹³å‡ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°']:.2f}")

        # ãƒãƒ£ãƒ³ãƒãƒ«åˆ†æ
        st.header("ãƒãƒ£ãƒ³ãƒãƒ«åˆ†æ")
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ãƒˆãƒƒãƒ—10ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ï¼‰")
            top_channels = df_filtered.groupby('channel_name')['posts'].sum().sort_values(ascending=False).head(10)
            fig = px.bar(top_channels, x=top_channels.index, y=top_channels.values)
            fig.update_layout(xaxis_title="ãƒãƒ£ãƒ³ãƒãƒ«å", yaxis_title="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°")
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            st.subheader("ãƒãƒ£ãƒ³ãƒãƒ«æˆé•·ç‡")
            channel_growth = calculate_channel_growth(df, start_datetime, end_datetime, previous_start_datetime)
            fig = px.bar(channel_growth, x=channel_growth.index, y=channel_growth.values)
            fig.update_layout(xaxis_title="ãƒãƒ£ãƒ³ãƒãƒ«å", yaxis_title="æˆé•·ç‡")
            st.plotly_chart(fig, use_container_width=True)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆåˆ†æ
        st.header("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆåˆ†æ")
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ãƒˆãƒƒãƒ—10ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼")
            top_users = df_filtered.groupby('display_name')['posts'].sum().sort_values(ascending=False).head(10)
            fig = px.bar(top_users, x=top_users.index, y='posts')
            fig.update_layout(xaxis_title="ãƒ¦ãƒ¼ã‚¶ãƒ¼å", yaxis_title="æŠ•ç¨¿æ•°")
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            st.subheader("ãƒ¦ãƒ¼ã‚¶ãƒ¼æˆé•·ç‡")
            user_growth = calculate_user_growth(df, start_datetime, end_datetime, previous_start_datetime)
            fig = px.bar(user_growth, x=user_growth.index, y=user_growth.values)
            fig.update_layout(xaxis_title="ãƒ¦ãƒ¼ã‚¶ãƒ¼å", yaxis_title="æˆé•·ç‡")
            st.plotly_chart(fig, use_container_width=True)

        # æ™‚ç³»åˆ—åˆ†æ
        st.header("æ™‚ç³»åˆ—åˆ†æ")
        activity_over_time = df_filtered.groupby('day')['posts'].sum().reset_index()
        fig = px.line(activity_over_time, x='day', y='posts')
        fig.update_layout(xaxis_title="æ—¥ä»˜", yaxis_title="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°")
        st.plotly_chart(fig, use_container_width=True)

        # æ›œæ—¥åˆ¥ãƒ»æ™‚é–“å¸¯åˆ¥åˆ†æ
        st.header("æ›œæ—¥åˆ¥ãƒ»æ™‚é–“å¸¯åˆ¥åˆ†æ")
        df_filtered['weekday'] = df_filtered['day'].dt.day_name()
        weekday_activity = df_filtered.groupby('weekday')['posts'].sum().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])
        fig = px.bar(weekday_activity, x=weekday_activity.index, y=weekday_activity.values)
        fig.update_layout(xaxis_title="æ›œæ—¥", yaxis_title="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°")
        st.plotly_chart(fig, use_container_width=True)


        # AIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        st.header("AIã«ã‚ˆã‚‹ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        if st.button("ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"):
            with st.spinner("AIãŒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­ã§ã™..."):
                report = generate_report(df, start_datetime, end_datetime, previous_start_datetime)
                if report:
                    st.markdown(report)
                else:
                    st.error("ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                    
        # Download processed data
        csv = df.to_csv(index=False)
        st.download_button(
            label="å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name="slack_analysis_results.csv",
            mime="text/csv",
        )

if __name__ == "__main__":
    main()